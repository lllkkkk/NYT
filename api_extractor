__author__ = 'Karthik'

import json
from urllib import request

# This is the fail save version I mean this is the base of the class function
"""
url = "http://api.nytimes.com/svc/search/v1/article?query=geo_facet:[NEW YORK STATE] &facets=des_facet,per_facet"
request_jsondata = request.urlopen("http://api.nytimes.com/svc/search/v2/articlesearch.json?q=immigration&api-key=cb2a40c7ef36cfa5b8d07d49170cf0b8%3A5%3A72188329")
strings = request_jsondata.read().decode('utf-8')
#opener = request.build_opener()
#f = opener.open(req)
json_obj = json.loads(strings)
print(json_obj)
"""



# I have returned everthing in this class so all we need to do is to figure out what we stuff we need from the json
class ApiExtractor:
    query = None
    begin_date = None
    end_date = None
    f1 = None
    api_url = "http://api.nytimes.com/svc/search/v2/articlesearch.json?"
    api_key = "api-key=cb2a40c7ef36cfa5b8d07d49170cf0b8%3A5%3A72188329"
    page = None
    f1 = None

    # Customize the start and the end date for the DataBase
    def assign_query(self, query):
        self.query = "q=" + query

    def assign_begin_date(self, begin):
        self.begin_date = "begin_date=" + begin

    def assign_query(self, end_date):
        self.end_date = "end_date="

    def assign_delimiter(self, f1):
        self.f1 = "f1="

    def page_range(self, number_range):
        self.page = "page="

    def construct_url(self):
        print("")
        if self.query is not None and self.begin_date is not None and self.end_date is not None and self.f1 is not None:
            urls = self.api_url + self.query + "&"+self.begin_date + "&"+self.end_date + "&" + self.api_key

        if self.query + "&" is None:
            print("No Query has been passed. Check the arguments that has been passed ")

        if self.end_date is None:
            urls.replace(self.end_date, "")

        if self.f1 is None:
            urls.replace(self.f1, "")
        return urls

    # Extract all the links from the query related topic
    def extract(self):
        try:
            rewuest = request.urlopen(self.api_url+"&"+self.api_key)
            #req_jsondata = request.urlopen(self.api_url + self.query + "&"+self.begin_date + "&"+self.end_date + "&" + self.api_key)
            tostring = rewuest.read().decode('utf-8')
            jobj = json.loads(tostring)
            print(jobj)
            for item in jobj["response"]["docs"]:
                print(item["web_url"])
                article_extractor(item["web_url"])
            for item in jobj["response"]["docs"]:
                pd = item["pub_date"]
                pud_date = pd[:10]
                present_date_st = pud_date.replace("-","")
                self.assign_present_date(present_date_st)


        except ValueError as e :
            print("Error occurred at the Extraction Function call :")

test = ApiExtractor()
test.extract()
